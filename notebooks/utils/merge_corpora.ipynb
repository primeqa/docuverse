{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task Summary\n",
    "\n",
    "Create a Jupyter notebook that merges two JSONL (JSON Lines) files based on a common 'id' key field.\n",
    "\n"
   ],
   "id": "708f987c25297f8c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# JSONL File Merger\n",
    "\n",
    "This notebook merges two JSONL files based on the 'id' key. It will:\n",
    "1. Load both JSONL files\n",
    "2. Parse JSON objects from each line\n",
    "3. Create dictionaries indexed by 'id'\n",
    "4. Merge the data based on matching IDs\n",
    "5. Save the merged result to a new JSONL file"
   ],
   "id": "95d670f2b704cf2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T15:34:25.611345Z",
     "start_time": "2025-10-21T15:34:25.609336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path"
   ],
   "id": "e4225aea513587fb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T15:34:27.782608Z",
     "start_time": "2025-10-21T15:34:27.779811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load JSONL file and return list of dictionaries\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                data.append(json.loads(line))\n",
    "    return data"
   ],
   "id": "ebf45ff436b263ec",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T15:34:28.371268Z",
     "start_time": "2025-10-21T15:34:28.365630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_jsonl_files(file1_path, file2_path, output_path, merge_strategy='update'):\n",
    "    \"\"\"\n",
    "    Merge two JSONL files based on 'id' key\n",
    "    \n",
    "    merge_strategy options:\n",
    "    - 'update': file2 values overwrite file1 values for matching keys\n",
    "    - 'combine': combine both objects, keeping all fields\n",
    "    \"\"\"\n",
    "\n",
    "    # Load both files\n",
    "    data1 = load_jsonl(file1_path)\n",
    "    data2 = load_jsonl(file2_path)\n",
    "\n",
    "    # Create dictionaries indexed by id\n",
    "    dict1 = {item['id']: item for item in data1 if 'id' in item}\n",
    "    dict2 = {item['id']: item for item in data2 if 'id' in item}\n",
    "\n",
    "    print(f\"File 1: {len(dict1)} records with 'id'\")\n",
    "    print(f\"File 2: {len(dict2)} records with 'id'\")\n",
    "\n",
    "    # Merge based on strategy\n",
    "    merged_data = {}\n",
    "\n",
    "    if merge_strategy == 'update':\n",
    "        merged_data = dict1.copy()\n",
    "        merged_data.update(dict2)\n",
    "    elif merge_strategy == 'combine':\n",
    "        all_ids = set(dict1.keys()) | set(dict2.keys())\n",
    "        for id_key in all_ids:\n",
    "            merged_obj = {}\n",
    "            if id_key in dict1:\n",
    "                merged_obj.update(dict1[id_key])\n",
    "            if id_key in dict2:\n",
    "                merged_obj.update(dict2[id_key])\n",
    "            merged_data[id_key] = merged_obj\n",
    "\n",
    "    print(f\"Merged: {len(merged_data)} records\")\n",
    "\n",
    "    # Save merged data\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        for record in merged_data.values():\n",
    "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    print(f\"Merged data saved to: {output_path}\")\n",
    "    return merged_data"
   ],
   "id": "dbac0380756a4440",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:34:42.222541Z",
     "start_time": "2025-10-21T16:34:39.505608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage - update these paths with your actual file paths\n",
    "file1_path = \"../benchmark/nq_new/corpus.train.top3.jsonl\"  # Replace with your first JSONL file path\n",
    "file2_path = \"../benchmark/nq_new/corpus.dev.top3.jsonl\"  # Replace with your second JSONL file path\n",
    "output_path = \"../benchmark/nq_new/corpus.top3.jsonl\"\n",
    "\n",
    "# Check if files exist (remove this check when using real files)\n",
    "if os.path.exists(file1_path) and os.path.exists(file2_path):\n",
    "    merged_data = merge_jsonl_files(file1_path, file2_path, output_path, merge_strategy='combine')\n",
    "else:\n",
    "    print(\"Please update the file paths with your actual JSONL files\")"
   ],
   "id": "bc7161c896ec53f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: 221675 records with 'id'\n",
      "File 2: 9058 records with 'id'\n",
      "Merged: 225669 records\n",
      "Merged data saved to: ../benchmark/nq_new/corpus.top3.jsonl\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:34:42.232917Z",
     "start_time": "2025-10-21T16:34:42.227902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_merge_results(file1_path, file2_path, merged_data):\n",
    "    \"\"\"Analyze the merge results and show statistics\"\"\"\n",
    "\n",
    "    data1 = load_jsonl(file1_path) if os.path.exists(file1_path) else []\n",
    "    data2 = load_jsonl(file2_path) if os.path.exists(file2_path) else []\n",
    "\n",
    "    dict1 = {item['id']: item for item in data1 if 'id' in item}\n",
    "    dict2 = {item['id']: item for item in data2 if 'id' in item}\n",
    "\n",
    "    common_ids = set(dict1.keys()) & set(dict2.keys())\n",
    "    only_in_file1 = set(dict1.keys()) - set(dict2.keys())\n",
    "    only_in_file2 = set(dict2.keys()) - set(dict1.keys())\n",
    "\n",
    "    print(\"Merge Analysis:\")\n",
    "    print(f\"Common IDs (in both files): {len(common_ids)}\")\n",
    "    print(f\"IDs only in file 1: {len(only_in_file1)}\")\n",
    "    print(f\"IDs only in file 2: {len(only_in_file2)}\")\n",
    "    print(f\"Total unique IDs: {len(merged_data)}\")\n",
    "\n",
    "    if len(common_ids) > 0:\n",
    "        print(f\"\\nExample common IDs: {list(common_ids)[:5]}\")\n"
   ],
   "id": "bc778997dc3088b6",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T16:34:44.002304Z",
     "start_time": "2025-10-21T16:34:43.168567Z"
    }
   },
   "cell_type": "code",
   "source": "analyze_merge_results(file1_path, file2_path, merged_data)",
   "id": "febabd07f5126869",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge Analysis:\n",
      "Common IDs (in both files): 5064\n",
      "IDs only in file 1: 216611\n",
      "IDs only in file 2: 3994\n",
      "Total unique IDs: 225669\n",
      "\n",
      "Example common IDs: ['838179391_5114-5371', '865846375_381-1468', '819463567_845-1452', '811129920_458-1708', '836158297_3788-4958']\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f4fa56ce028fbcb3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
